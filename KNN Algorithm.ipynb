{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-create the KNN Algorithm\n",
    "## Steven Glover\n",
    "***\n",
    "To recreate the KNN algorithm I created a series of functions that were leveraged by a single wrapper function. In this notebook, I first used Iris data sets to test this functionality. I prototyped the titanic dataset in another notebook, but the code included below and in the attached script are identical. I demonstrate the wrapper function using both the Titanic dataset and the Iris dataset at the end of this workbook. <br>\n",
    "<br>**Preprocessing:**\n",
    "1.\tdata_type_preprocessing: The function breaks the data frame into a train / split, converts the categorical variables to dummies, and normalizes the X-test and X-Train subsets to be on a zero to one scale.  To manage different data types, the function will behave differently depending on the input parameters. The var_type parameter indicates whether the inputted data frame consists of only categorical variables, only continuous variables, or a mixture between the two. If the function is given only categorical variables, the categorical variables will be converted to dummies and the test / train split along with the column names is returned. If the function is given only continuous variables, the variables will be normalized, and the test / train split along with the column names is returned. If the function is given a mixed data frame the user must also include lists identifying which columns are continuous and categorical in the continuous_list and categorical_list arguments. For mixed data frames, the function will return the test / train, the column names, the indexes of the continuous variables and the indexes of the categorical variables.  <br>\n",
    "<br>**Distance Measures:**\n",
    "2.\tminkowski_distance – will compute the minkowki distance between two arrays\n",
    "3.\tminkowski_point_array : (To be used in conjunction with the Gower Distance)  - The function returns an array of the Minkowski distances between each continuous point of two arrays. This is needed because the Gower Distance requires that these point distance measures are normalized before the Gower Distance is calculated. \n",
    "4.\tjaccard_distance – will compute the jaccard distance for categorical variables\n",
    "5.\tgower_distance - The function returns the distances needed to calculate the Gower distance.  Note, the return is not a single distance measure because of an additional normalizing step for the continuous distance measures.  The function returns 3 variables: 1 the Jaccard distance measure for the categorical variables, 2.  an array of Minkowski distance measure between each continuous point, 3. the denominator for the Gower distance calculation. <br>\n",
    "<br>**KNN Predictions:**\n",
    "6.\tknn_predictions: The function calculates the distance measures for each observation in the test set to each observation in the training set. An array of distance measures is created for each observation in the test. The function then returns the indexes of the K smallest distances in the array. Using these indexes, we are able to determine the y values associated with the smallest distances measures, which are stored in another array. We then obtain the vote for the prediction using a combination of the numpy argmax function and the numpy unique function. This process is repeated for each of the observation in the test set and the predictions are stored to a list with every iteration. <br>\n",
    "<br>**Prediction Accuracy Report**\n",
    "7.\tThe function returns the accuracy score, precision / recall tables, and a confusion matrix for the predictions. <br>\n",
    "<br>**The Wrapper Function**\n",
    "8.\tComplete_KNN: The function wraps all the above functions together to provide preprocessing, generate predictions using the KNN algorithm, and an accuracy report. The function takes the following arguments:\n",
    "    - Df – the data frame the user is working with\n",
    "    - y – the name of the y variable as a string\n",
    "    - var_type – identifies the datatypes of the predictors and takes the following inputs: continuous, categorical or mixed. It is continuous by default.\n",
    "    - continuous_list = This field is required for data frames of mixed datatypes, such as the titanic dataset. The argument takes a list with the column names of the continuous variables.\n",
    "    - categorical_list = This field is required for data frames of mixed datatypes. The argument takes a list with the column names of the categorical variables.\n",
    "    - k = the number of nearest neighbors to calculate\n",
    "     - distance_measure = is the distance measure used to determine the nearest neighbors. It is ‘euclidean’ by default. It will take ‘euclidean’, ‘manhattan’, ‘jaccard’, and ‘gower.’  \n",
    "\n",
    "**<font color = red> Please note: </font> ** the user is required to know which measures to use for which data type. Errors may result if the user tries to compute the Gower distance on an all continuous or all categorical data frame. Additionally, using the Jaccard distance for an all continuous data frame will produce errors as well. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns:  Index(['SEPAL_LENGTH', 'SEPAL_WIDTH', 'PETAL_LENGTH', 'PETAL_WIDTH', 'TARGET'], dtype='object') \n",
      "\n",
      "shape:  (150, 5) \n",
      "\n",
      "null: \n",
      " SEPAL_LENGTH    0\n",
      "SEPAL_WIDTH     0\n",
      "PETAL_LENGTH    0\n",
      "PETAL_WIDTH     0\n",
      "TARGET          0\n",
      "dtype: int64\n",
      "-------------------------------\n",
      "Unique Values:  SEPAL_LENGTH    35\n",
      "SEPAL_WIDTH     23\n",
      "PETAL_LENGTH    43\n",
      "PETAL_WIDTH     22\n",
      "TARGET           3\n",
      "dtype: int64\n",
      "SEPAL_LENGTH \n",
      " [ 5.1  4.9  4.7  4.6  5.   5.4  4.4  4.8  4.3  5.8  5.7  5.2  5.5  4.5  5.3\n",
      "  7.   6.4  6.9  6.5  6.3  6.6  5.9  6.   6.1  5.6  6.7  6.2  6.8  7.1  7.6\n",
      "  7.3  7.2  7.7  7.4  7.9]\n",
      "---------------\n",
      "SEPAL_WIDTH \n",
      " [ 3.5  3.   3.2  3.1  3.6  3.9  3.4  2.9  3.7  4.   4.4  3.8  3.3  4.1  4.2\n",
      "  2.3  2.8  2.4  2.7  2.   2.2  2.5  2.6]\n",
      "---------------\n",
      "PETAL_LENGTH \n",
      " [ 1.4  1.3  1.5  1.7  1.6  1.1  1.2  1.   1.9  4.7  4.5  4.9  4.   4.6  3.3\n",
      "  3.9  3.5  4.2  3.6  4.4  4.1  4.8  4.3  5.   3.8  3.7  5.1  3.   6.   5.9\n",
      "  5.6  5.8  6.6  6.3  6.1  5.3  5.5  6.7  6.9  5.7  6.4  5.4  5.2]\n",
      "---------------\n",
      "PETAL_WIDTH \n",
      " [ 0.2  0.4  0.3  0.1  0.5  0.6  1.4  1.5  1.3  1.6  1.   1.1  1.8  1.2  1.7\n",
      "  2.5  1.9  2.1  2.2  2.   2.4  2.3]\n",
      "---------------\n",
      "TARGET \n",
      " [0 1 2]\n",
      "---------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEPAL_LENGTH</th>\n",
       "      <th>SEPAL_WIDTH</th>\n",
       "      <th>PETAL_LENGTH</th>\n",
       "      <th>PETAL_WIDTH</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEPAL_LENGTH  SEPAL_WIDTH  PETAL_LENGTH  PETAL_WIDTH  TARGET\n",
       "0           5.1          3.5           1.4          0.2       0\n",
       "1           4.9          3.0           1.4          0.2       0\n",
       "2           4.7          3.2           1.3          0.2       0\n",
       "3           4.6          3.1           1.5          0.2       0\n",
       "4           5.0          3.6           1.4          0.2       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "#import the Iris Dataset\n",
    "iris = datasets.load_iris()\n",
    "#create a dataframe of the iris dataset\n",
    "data = pd.DataFrame(data=iris.data, columns=['SEPAL_LENGTH','SEPAL_WIDTH','PETAL_LENGTH','PETAL_WIDTH'])\n",
    "data['TARGET'] = iris.target\n",
    "\n",
    "#print Information about the dataset\n",
    "print('columns: ',data.columns,'\\n')\n",
    "print('shape: ', data.shape,'\\n')\n",
    "print('null: \\n', pd.isnull(data).sum())\n",
    "print('-------------------------------')\n",
    "print('Unique Values: ', data.nunique())\n",
    "\n",
    "for i in data.columns.tolist():\n",
    "    print(i,'\\n',data[i].unique())\n",
    "    print('---------------')\n",
    "    \n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = blue> The following functions and code is the prototyping for the Complete_KNN function in the .py script file </font>\n",
    "The KNN script file will be called at the end of the file to ensure that it works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Train Test Split\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_type_preprocessing(df,y, var_type = 'continuous',\n",
    "                            continuous_list = None, categorical_list = None, categorical_only= False):\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    ''' The following function will preprocess the data and create a train test split.\n",
    "    It will be able to handle dataframes that are all categorical, all continuous, or mixed.\n",
    "    it will create dummies for categorical variables. It will normalize continous variables.\n",
    "    it will also create a train test split. For mixed dataframes it will return the indexes of \n",
    "    the continuous and categorical variables.\n",
    "    \n",
    "    var_type\n",
    "    --------\n",
    "    var_type = 'continuous' (by default. Indicates only continous variables in the dataframe)\n",
    "    var_type = 'categorical' ('Indicates only a categorical dataframe)\n",
    "    var_type = 'Mixed ('Indicates both categorical and continous variables present. \n",
    "                        Requires both categorical list, and continuous lists.)\n",
    "    '''\n",
    "    \n",
    "    #get variable names from the function\n",
    "    #------------------------------------\n",
    "    \n",
    "    #get the y col\n",
    "    y_col = y\n",
    "    \n",
    "    #create the y array \n",
    "    y = np.array(df[y].astype(str))\n",
    "    \n",
    "    \"\"\" Determine the type variables we are working with and \n",
    "    process accrodingly\"\"\"\n",
    "    \n",
    "    if var_type == 'mixed':\n",
    "        #get categorical & continuous variables\n",
    "        cont = continuous_list\n",
    "        cat = categorical_list\n",
    "        \n",
    "        #subset continuous\n",
    "        cont_df = df[cont]\n",
    "        \n",
    "        #get the length of continuous and categorical to slice arrays\n",
    "        split_position = len(cont)\n",
    "        \n",
    "        #get dummies for categorical variables\n",
    "        cat_df = pd.get_dummies(df[cat].astype(str))\n",
    "    \n",
    "        #recreate the dataframe with dummies\n",
    "        X = pd.merge(cont_df,cat_df, how = 'left', left_index=True, right_index = True)\n",
    "        \n",
    "    elif var_type == 'categorical':\n",
    "        #create a dataframe of dummy variables that do not include y\n",
    "        X = pd.get_dummies(df[categorical_list])\n",
    "        \n",
    "    elif var_type == 'continuous':\n",
    "        X = df[continuous_list]\n",
    "    \n",
    "    \n",
    "    # Get column names\n",
    "    col_names = X.columns\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # Create the train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    \n",
    "    #preprocess continuous variables\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "        \n",
    "    if var_type == 'mixed':\n",
    "        #idenify the array index of categorical and continuous columns\n",
    "        cont_idx = [i for i in range(split_position)]\n",
    "        cat_idx = [i for i in range(split_position, col_names.shape[0])] \n",
    "        return X_train, X_test, y_train, y_test, col_names, cont_idx, cat_idx\n",
    "    else:\n",
    "        return X_train, X_test, y_train, y_test, col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, col_names = data_type_preprocessing(data, y = 'TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEPAL_LENGTH</th>\n",
       "      <th>SEPAL_WIDTH</th>\n",
       "      <th>PETAL_LENGTH</th>\n",
       "      <th>PETAL_WIDTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.388889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.559322</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SEPAL_LENGTH  SEPAL_WIDTH  PETAL_LENGTH  PETAL_WIDTH\n",
       "0        0.722222     0.458333      0.745763     0.833333\n",
       "1        0.250000     0.875000      0.084746     0.000000\n",
       "2        0.583333     0.291667      0.728814     0.750000\n",
       "3        0.166667     0.458333      0.084746     0.000000\n",
       "4        0.472222     0.375000      0.593220     0.583333\n",
       "5        0.805556     0.416667      0.813559     0.625000\n",
       "6        0.250000     0.291667      0.491525     0.541667\n",
       "7        0.388889     1.000000      0.084746     0.125000\n",
       "8        0.194444     0.583333      0.101695     0.125000\n",
       "9        0.305556     0.708333      0.084746     0.041667\n",
       "10       0.500000     0.375000      0.627119     0.541667\n",
       "11       0.666667     0.416667      0.677966     0.666667\n",
       "12       0.611111     0.416667      0.813559     0.875000\n",
       "13       0.555556     0.125000      0.576271     0.500000\n",
       "14       0.722222     0.458333      0.661017     0.583333\n",
       "15       0.222222     0.750000      0.101695     0.041667\n",
       "16       0.194444     0.541667      0.067797     0.041667\n",
       "17       0.222222     0.208333      0.338983     0.416667\n",
       "18       0.222222     0.750000      0.084746     0.083333\n",
       "19       0.694444     0.416667      0.762712     0.833333\n",
       "20       0.361111     0.375000      0.440678     0.500000\n",
       "21       0.194444     0.000000      0.423729     0.375000\n",
       "22       0.444444     0.416667      0.694915     0.708333\n",
       "23       0.138889     0.416667      0.067797     0.083333\n",
       "24       0.333333     0.125000      0.508475     0.500000\n",
       "25       0.444444     0.416667      0.542373     0.583333\n",
       "26       0.333333     0.208333      0.508475     0.500000\n",
       "27       0.555556     0.375000      0.779661     0.708333\n",
       "28       0.222222     0.625000      0.067797     0.083333\n",
       "29       0.555556     0.333333      0.694915     0.583333\n",
       "..            ...          ...           ...          ...\n",
       "90       0.666667     0.458333      0.627119     0.583333\n",
       "91       0.416667     0.250000      0.508475     0.458333\n",
       "92       0.166667     0.208333      0.593220     0.666667\n",
       "93       0.388889     0.416667      0.542373     0.458333\n",
       "94       0.361111     0.416667      0.593220     0.583333\n",
       "95       0.416667     0.291667      0.694915     0.750000\n",
       "96       0.583333     0.500000      0.593220     0.583333\n",
       "97       0.916667     0.416667      0.949153     0.833333\n",
       "98       0.138889     0.583333      0.152542     0.041667\n",
       "99       0.666667     0.458333      0.779661     0.958333\n",
       "100      0.527778     0.083333      0.593220     0.583333\n",
       "101      0.083333     0.500000      0.067797     0.041667\n",
       "102      0.305556     0.416667      0.593220     0.583333\n",
       "103      0.694444     0.333333      0.644068     0.541667\n",
       "104      0.611111     0.416667      0.762712     0.708333\n",
       "105      0.027778     0.416667      0.050847     0.041667\n",
       "106      0.388889     0.750000      0.118644     0.083333\n",
       "107      0.694444     0.500000      0.830508     0.916667\n",
       "108      0.555556     0.541667      0.627119     0.625000\n",
       "109      0.388889     0.375000      0.542373     0.500000\n",
       "110      0.305556     0.583333      0.084746     0.125000\n",
       "111      0.416667     0.291667      0.491525     0.458333\n",
       "112      0.111111     0.500000      0.101695     0.041667\n",
       "113      0.805556     0.666667      0.864407     1.000000\n",
       "114      0.500000     0.416667      0.610169     0.541667\n",
       "115      0.611111     0.416667      0.711864     0.791667\n",
       "116      0.722222     0.500000      0.796610     0.916667\n",
       "117      0.527778     0.375000      0.559322     0.500000\n",
       "118      0.944444     0.333333      0.966102     0.791667\n",
       "119      0.194444     0.416667      0.101695     0.041667\n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = X_train,columns=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Distance Measures \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minkowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import minkowski\n",
    "from scipy.spatial.distance import jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minkowski Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = X_train[0,:]\n",
    "B = X_train[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2361200547612616"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True minkowski Distance between two arrays\n",
    "def minkowski_distance(A, B, p =2):\n",
    "    p = 2\n",
    "    diff_abs = np.abs(A - B)\n",
    "    to_the_p = diff_abs**p\n",
    "    sum_dist = sum(to_the_p)\n",
    "    sum_div_p = sum_dist**(1/p)\n",
    "    return sum_div_p\n",
    "\n",
    "minkowski_distance(A, B, p =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2361200547612616"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scipy check\n",
    "minkowski(A , B, p= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minkowski Distance between two points for the Gower\n",
    "def minkowski_point_array(A, B, p = 2):\n",
    "    '''This function will be used in the gower distance calculation.\n",
    "    it differs from the true minkowsi in that calculates the minkowski distance\n",
    "    between two points rather than between two arrays'''\n",
    "    #absolute value of the difference\n",
    "    diff_abs = np.abs(A - B)\n",
    "    #to the p\n",
    "    to_the_p = diff_abs**p\n",
    "    #each point in the array raised to the value of 1/p\n",
    "    dist_raised_1div_p = to_the_p**(1/p)\n",
    "    return dist_raised_1div_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47222222,  0.41666667,  0.66101695,  0.83333333])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minkowski_point_array(A, B, p = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(A, B):\n",
    "    a = []\n",
    "    b = []\n",
    "    c = []\n",
    "    for index in range(len(A)):\n",
    "        if A[index] == 1 and B[index] == 1:\n",
    "            a.append(1)\n",
    "        elif A[index] == 1 and B[index] == 0:\n",
    "            b.append(1)\n",
    "        elif A[index] == 0 and B[index] == 1:\n",
    "            c.append(1)\n",
    "    return (sum(b) + sum(c))/(sum(a) + sum(b) + sum(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gower Distance function\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gower_distance(A, B, cont_idx, cat_idx, p = 2):\n",
    "    \"\"\"This function will return the jaccard distance calculation, an array of the minkowski point calculations.\n",
    "    note: the minkowski 'point' distances are not summed. Just an array of the gower distances from point to point\n",
    "    is returned. The function was built this way because we need to nomalize the gower array before computing the\n",
    "    gower distances. The function also returns the demominator for the gower distance calculations\n",
    "    (+ 1 for each continous and a 1 if categorical variables exist)\"\"\"\n",
    "    denominator = len(cont_idx) + 1\n",
    "    return jaccard_distance(A[cat_idx], B[cat_idx]), minkowski_point_array(A[cont_idx], B[cont_idx],p = 2), denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The  KNN Predictions\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. calcualte the distances and store them to a list\n",
    "def knn_predictions(X_train, X_test, y_train, y_test, col_names, \n",
    "                    cont_idx = None, cat_idx = None, k = 5, distance = 'gower'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Distance_measures\n",
    "    -----------------\n",
    "    1. 'gower'\n",
    "    2. 'jaccard'\n",
    "    3. 'euclidean'\n",
    "    4. 'manhattan'\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    predictions = []\n",
    "    for test_index in range(X_test.shape[0]):\n",
    "        test = X_test[test_index,:]\n",
    "        distances = []\n",
    "        \n",
    "        \"\"\"The following section will populate the distance for each observation in the training\n",
    "        set to the current test observation. Due to the normalization of the distances prior to \n",
    "        concatenation with the jaccard caculation, the gower distance has a much lengthy procedure.\"\"\"\n",
    "        \n",
    "        if distance == 'gower':\n",
    "        #calculate the distance of the test line to all of the other training lines\n",
    "            for train_index in range(X_train.shape[0]):\n",
    "                #indentify the training line\n",
    "                train = X_train[train_index,:]\n",
    "\n",
    "                #Calcuates the Gower Distance\n",
    "\n",
    "                '''get the an the jaccard distances calculations, \n",
    "                an array of the minkowski distance calculations for each point, and \n",
    "                the denominator'''\n",
    "\n",
    "                jaccard, gower_point_dist, denominator = gower_distance(test, train, cont_idx, cat_idx)\n",
    "                #store each calculation to an array\n",
    "                if train_index == 0:\n",
    "                    jaccard_array = np.array(jaccard).reshape(1,1)\n",
    "                    gower_array = gower_point_dist.reshape(1,len(cont_idx))\n",
    "                else:\n",
    "                    jaccard_array = np.append(jaccard_array, np.array(jaccard).reshape(1,1),axis=0)\n",
    "                    gower_array = np.append(gower_array,gower_point_dist.reshape(1,len(cont_idx)),axis=0)\n",
    "\n",
    "            #normalize the gower distance to be on a zero to one scale\n",
    "            scaler = MinMaxScaler()\n",
    "            gower_array = scaler.fit_transform(gower_array)\n",
    "\n",
    "            #combine the jackard distance calcuation wtih the normalized gower array\n",
    "            normalized_gower_array = np.hstack((jaccard_array, gower_array))\n",
    "            '''CALCULATE ALL THE GOWER DISTANCES LINE BY LINE AND APPEND TO A LIST''' \n",
    "            for i in range(normalized_gower_array.shape[0]):\n",
    "                distances.append((sum(normalized_gower_array[i,:]))/denominator)\n",
    "                \n",
    "        #create an array of manhattan distances        \n",
    "        elif distance == 'manhattan':\n",
    "            for train_index in range(X_train.shape[0]):\n",
    "                train = X_train[train_index,:]\n",
    "                distances.append(minkowski_distance(test, train, p =1))\n",
    "                    \n",
    "        #create an array of euclidean distances \n",
    "        elif distance == 'euclidean':\n",
    "            for train_index in range(X_train.shape[0]):\n",
    "                train = X_train[train_index,:]\n",
    "                distances.append(minkowski_distance(test, train, p =2))\n",
    "                    \n",
    "        #create an array of manhattan distances \n",
    "        elif distance == 'jaccard':\n",
    "            for train_index in range(X_train.shape[0]):\n",
    "                train = X_train[train_index,:]\n",
    "                distances.append(jaccard_distance(test, train))\n",
    "                    \n",
    "        # 3. get the indexes for the nearest neighbors\n",
    "        prediction_index = np.array(distances).argsort()[:k]\n",
    "\n",
    "        # 4. get all the predictions values\n",
    "        prediction_values = y_train[prediction_index]\n",
    "\n",
    "        # 5. Use the numpy unique function to determine which prediction appeared the most\n",
    "        # returns the position in the unique array with the maximum count\n",
    "        max_index = np.argmax(np.unique(prediction_values , return_counts=True)[1])\n",
    "\n",
    "        # 6. returns the value of the maximum count\n",
    "        prediction = np.unique(prediction_values , return_counts=True)[0][max_index]\n",
    "\n",
    "        # 7. store the prediction to the list\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "    return np.array(predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = knn_predictions(X_train, X_test, y_train, y_test, col_names, k = 5, distance = 'euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuaracy_report(y_test, predictions):\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    print('The Accuracy Score is: ',np.array(np.sum(np.equal(predictions, y_test))) / y_test.shape[0],'\\n')\n",
    "    print('The Classification Report')\n",
    "    print('-------------------------')\n",
    "    print(classification_report(y_test, predictions),'\\n')\n",
    "    print('The Confusion Matrix')\n",
    "    print('-------------------------')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, predictions)).apply(lambda x: x / sum(x), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score is:  0.966666666667 \n",
      "\n",
      "The Classification Report\n",
      "-------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       1.00      0.90      0.95        10\n",
      "          2       0.83      1.00      0.91         5\n",
      "\n",
      "avg / total       0.97      0.97      0.97        30\n",
      " \n",
      "\n",
      "The Confusion Matrix\n",
      "-------------------------\n",
      "     0    1    2\n",
      "0  1.0  0.0  0.0\n",
      "1  0.0  0.9  0.1\n",
      "2  0.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "accuaracy_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing it all together for a complete KNN Function\n",
    "The below was used to draft the wrapper function for the KNN.\n",
    "I added all of these functions to a single script to be used as a library\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The Complete KNN Wrapper Fuction\"\"\"\n",
    "\"\"\"--------------------------------\"\"\"\n",
    "def Complete_KNN(df, y, var_type = 'continuous',\n",
    "                 continuous_list = None, categorical_list = None, categorical_only= False,\n",
    "                 k = 5, distance_measure = 'euclidean'):\n",
    "    \n",
    "    #import packages\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    # the index variables will be populated if we are using a mixed type\n",
    "    cont_idx = None\n",
    "    cat_idx = None\n",
    "    \n",
    "    # Step 1 - Preprocessing\n",
    "    if var_type == 'mixed':\n",
    "        X_train, X_test, y_train, y_test, col_names, cont_idx, cat_idx = data_type_preprocessing(df,y, var_type = var_type,\n",
    "                                                                                        continuous_list = continuous_list,\n",
    "                                                                                        categorical_list = categorical_list,\n",
    "                                                                                        categorical_only= categorical_only)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test, col_names = data_type_preprocessing(df,y, var_type = var_type,\n",
    "                                                                                        continuous_list = continuous_list,\n",
    "                                                                                        categorical_list = categorical_list,\n",
    "                                                                                        categorical_only= categorical_only)\n",
    "        \n",
    "    # Step 2 - Generate Predictions\n",
    "    predictions = knn_predictions(X_train, X_test, y_train, y_test, col_names, \n",
    "                                 cont_idx = cont_idx, cat_idx = cat_idx,\n",
    "                                 k = k, distance = distance_measure)\n",
    "    \n",
    "    \n",
    "    #Step 3 - Print Accuarcy Report\n",
    "    accuaracy_report(y_test, predictions)\n",
    "    \n",
    "    # Step 4 - Return Predictions\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Complete_KNN function from the KNN_Glover.py Script File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score is:  0.966666666667 \n",
      "\n",
      "The Classification Report\n",
      "-------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         7\n",
      "          1       1.00      0.92      0.96        13\n",
      "          2       0.91      1.00      0.95        10\n",
      "\n",
      "avg / total       0.97      0.97      0.97        30\n",
      " \n",
      "\n",
      "The Confusion Matrix\n",
      "-------------------------\n",
      "     0         1         2\n",
      "0  1.0  0.000000  0.000000\n",
      "1  0.0  0.923077  0.076923\n",
      "2  0.0  0.000000  1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '0', '1', '0', '1', '2', '2', '2', '2', '2', '0', '2',\n",
       "       '1', '1', '0', '1', '1', '0', '1', '2', '2', '1', '1', '1', '0',\n",
       "       '1', '2', '0', '2'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from KNN_Glover import Complete_KNN\n",
    "Complete_KNN(data, y = 'TARGET', var_type = 'continuous',\n",
    "                 continuous_list = None, categorical_list = None, categorical_only= False,\n",
    "                 k = 5, distance_measure = 'euclidean' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "***\n",
    "# Titanic Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns:  Index(['pclass', 'survived', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket',\n",
      "       'fare', 'cabin', 'embarked', 'boat', 'body', 'home.dest'],\n",
      "      dtype='object') \n",
      "\n",
      "shape:  (1310, 14) \n",
      "\n",
      "null: \n",
      " pclass          1\n",
      "survived        1\n",
      "name            1\n",
      "sex             1\n",
      "age           264\n",
      "sibsp           1\n",
      "parch           1\n",
      "ticket          1\n",
      "fare            2\n",
      "cabin        1015\n",
      "embarked        3\n",
      "boat          824\n",
      "body         1189\n",
      "home.dest     565\n",
      "dtype: int64\n",
      "-------------------------------\n",
      "Unique Values:  pclass          3\n",
      "survived        2\n",
      "name         1307\n",
      "sex             2\n",
      "age            98\n",
      "sibsp           7\n",
      "parch           8\n",
      "ticket        929\n",
      "fare          281\n",
      "cabin         186\n",
      "embarked        3\n",
      "boat           27\n",
      "body          121\n",
      "home.dest     369\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/Steven Glover/Jupyter Notebooks/Fall Semester/KNN/titanic3.csv')\n",
    "print('columns: ',data.columns,'\\n')\n",
    "print('shape: ', data.shape,'\\n')\n",
    "print('null: \\n', pd.isnull(data).sum())\n",
    "print('-------------------------------')\n",
    "print('Unique Values: ', data.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Name, Cabin, Ticket, Boat,  Get Rid of Null Values, and Inspect Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1043 entries, 0 to 1308\n",
      "Data columns (total 8 columns):\n",
      "pclass      1043 non-null float64\n",
      "survived    1043 non-null float64\n",
      "sex         1043 non-null object\n",
      "age         1043 non-null float64\n",
      "sibsp       1043 non-null float64\n",
      "parch       1043 non-null float64\n",
      "fare        1043 non-null float64\n",
      "embarked    1043 non-null object\n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 73.3+ KB\n",
      "pclass \n",
      " [ 1.  2.  3.]\n",
      "---------------\n",
      "survived \n",
      " [ 1.  0.]\n",
      "---------------\n",
      "sex \n",
      " ['female' 'male']\n",
      "---------------\n",
      "age \n",
      " [ 29.       0.9167   2.      30.      25.      48.      63.      39.      53.\n",
      "  71.      47.      18.      24.      26.      80.      50.      32.      36.\n",
      "  37.      42.      19.      35.      28.      45.      40.      58.      22.\n",
      "  41.      44.      59.      60.      33.      17.      11.      14.      49.\n",
      "  76.      46.      27.      64.      55.      70.      38.      51.      31.\n",
      "   4.      54.      23.      43.      52.      16.      32.5     21.      15.\n",
      "  65.      28.5     45.5     56.      13.      61.      34.       6.      57.\n",
      "  62.      67.       1.      12.      20.       0.8333   8.       0.6667\n",
      "   7.       3.      36.5     18.5      5.      66.       9.       0.75\n",
      "  70.5     22.5      0.3333   0.1667  40.5     10.      23.5     34.5     20.5\n",
      "  30.5     55.5     38.5     14.5     24.5     74.       0.4167  11.5     26.5   ]\n",
      "---------------\n",
      "sibsp \n",
      " [ 0.  1.  2.  3.  4.  5.  8.]\n",
      "---------------\n",
      "parch \n",
      " [ 0.  2.  1.  4.  3.  5.  6.]\n",
      "---------------\n",
      "fare \n",
      " [ 211.3375  151.55     26.55     77.9583    0.       51.4792   49.5042\n",
      "  227.525    69.3      78.85     30.      247.5208   76.2917   75.2417\n",
      "   52.5542  221.7792   26.       91.0792  135.6333   35.5      31.\n",
      "  164.8667  262.375    55.       30.5      50.4958   27.7208  134.5\n",
      "   26.2875   27.4458  512.3292    5.       47.1     120.       61.175\n",
      "   53.1      86.5      29.7     136.7792   25.5875   83.1583   25.7      71.\n",
      "   71.2833   52.       57.       81.8583  106.425    39.6      56.9292\n",
      "   78.2667   31.6792   26.3875   27.75    263.      133.65     49.5      79.2\n",
      "   38.5     211.5      59.4      89.1042   34.6542   28.5     153.4625\n",
      "   63.3583   55.4417   76.7292   83.475    93.5      42.5      50.\n",
      "   57.9792   90.       28.7125   51.8625   25.9292   39.4      45.5\n",
      "  146.5208   82.1708   57.75     42.4     113.275    26.2833  108.9\n",
      "   61.9792   66.6      40.125    55.9      30.6958   60.       82.2667\n",
      "   32.3208   79.65    110.8833   28.5375   33.5      34.0208   75.25\n",
      "   77.2875   61.3792   24.       13.       11.5      10.5      12.525    39.\n",
      "   29.       21.       13.5      26.25     36.75     73.5      31.5      23.\n",
      "   32.5      13.8583   14.5      33.       65.       16.       12.275    27.\n",
      "   15.       13.7917   12.35     41.5792   12.       12.875    37.0042\n",
      "   19.5      14.        9.6875   30.0708   13.8625   12.7375   15.0333\n",
      "   15.0458   18.75     12.65     15.75      7.55     20.25      7.65\n",
      "    7.925     7.2292    7.25      8.05      9.475     9.35     18.7875\n",
      "    7.8875    7.05      8.3      22.525     7.8542   31.275     7.775\n",
      "    7.7958    7.8958   17.8      31.3875    7.225    14.4583   15.85\n",
      "   19.2583   14.4542    7.8792    4.0125   56.4958    7.75     15.2458\n",
      "   15.5      16.1       7.725     7.0458    7.2833    7.8208    6.75\n",
      "    8.6625    7.7333    7.4958    7.6292   15.9       8.1583   10.5167\n",
      "   10.1708    6.95     14.4      24.15     17.4       9.5      20.575\n",
      "   12.475    13.9       6.975    15.1      34.375     7.7417   20.525\n",
      "    7.85     46.9       8.3625    9.8458    8.85     14.1083    8.9625\n",
      "   12.2875    6.45      7.0542    6.4958    8.6542   11.1333    9.825\n",
      "    7.125     8.4333    7.5208   13.4167    7.8292   22.025    12.1833\n",
      "    9.5875    9.4833    6.4375   15.55      7.5792    7.1417    8.0292\n",
      "   15.7417   11.2417    7.8       6.2375    9.225     3.1708    8.4042\n",
      "    9.2167    8.6833   21.075    39.6875   13.775    29.125    20.2125\n",
      "   69.55      9.325    16.7      27.9       9.8375   10.4625    8.5167\n",
      "    9.8417    9.       18.        7.        7.875 ]\n",
      "---------------\n",
      "embarked \n",
      " ['S' 'C' 'Q']\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(['name','cabin','ticket','boat','home.dest','body'], axis = 1)\n",
    "data = data.dropna()\n",
    "data.info()\n",
    "\n",
    "for i in data.columns.tolist():\n",
    "    print(i,'\\n',data[i].unique())\n",
    "    print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the Complete_KNN Algorithm via KNN.py Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score is:  0.803827751196 \n",
      "\n",
      "The Classification Report\n",
      "-------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.85      0.84       123\n",
      "        1.0       0.77      0.74      0.76        86\n",
      "\n",
      "avg / total       0.80      0.80      0.80       209\n",
      " \n",
      "\n",
      "The Confusion Matrix\n",
      "-------------------------\n",
      "          0         1\n",
      "0  0.845528  0.154472\n",
      "1  0.255814  0.744186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0.0', '0.0', '0.0', '0.0', '1.0', '1.0', '1.0', '1.0', '0.0',\n",
       "       '0.0', '1.0', '1.0', '1.0', '1.0', '1.0', '0.0', '0.0', '0.0',\n",
       "       '1.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '1.0', '1.0',\n",
       "       '0.0', '1.0', '1.0', '0.0', '1.0', '0.0', '1.0', '0.0', '1.0',\n",
       "       '0.0', '1.0', '0.0', '1.0', '1.0', '0.0', '1.0', '1.0', '0.0',\n",
       "       '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '0.0', '1.0', '0.0',\n",
       "       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0',\n",
       "       '0.0', '1.0', '0.0', '1.0', '1.0', '0.0', '1.0', '1.0', '0.0',\n",
       "       '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0',\n",
       "       '1.0', '0.0', '1.0', '0.0', '1.0', '1.0', '0.0', '0.0', '1.0',\n",
       "       '0.0', '0.0', '0.0', '1.0', '1.0', '0.0', '1.0', '0.0', '0.0',\n",
       "       '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "       '0.0', '1.0', '0.0', '0.0', '0.0', '1.0', '1.0', '1.0', '0.0',\n",
       "       '0.0', '0.0', '0.0', '1.0', '1.0', '0.0', '0.0', '1.0', '0.0',\n",
       "       '0.0', '0.0', '1.0', '0.0', '0.0', '1.0', '0.0', '0.0', '1.0',\n",
       "       '0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '1.0', '0.0', '1.0',\n",
       "       '0.0', '0.0', '1.0', '0.0', '1.0', '1.0', '1.0', '1.0', '0.0',\n",
       "       '1.0', '0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0',\n",
       "       '1.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '1.0', '0.0',\n",
       "       '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '1.0', '0.0', '1.0',\n",
       "       '1.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '1.0', '0.0',\n",
       "       '0.0', '0.0'],\n",
       "      dtype='<U3')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from KNN import Complete_KNN\n",
    "\n",
    "Complete_KNN(data, y = 'survived', var_type = 'mixed',\n",
    "                 continuous_list = ['age', 'sibsp', 'parch', 'fare'],\n",
    "                 categorical_list = ['pclass','sex','embarked'],\n",
    "                 categorical_only= False,\n",
    "                 k = 5, distance_measure = 'gower' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 275.4,
   "position": {
    "height": "562px",
    "left": "1177px",
    "right": "19.6px",
    "top": "108px",
    "width": "339px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
